<!DOCTYPE html>
<html lang="en">

<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143354296-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-143354296-1');
    </script>

    <title>DVGO</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>DVGO</title>
    <meta name="keywords" content="DVGO, direct voxel grid optimization, voxel grid, NeRF">
    <meta name="description" content="Fast 3D scenes reconstruction from multiple images. DVGO supports bounded inward-facing, unbounded inward-facing (unbounded 360), and forward-facing capturing.">
    <meta name="google-site-verification" content="zTn5k4uR8M5ulbD97RtehwXhTTfyIYD4zgdiiQsMn6Q" />
    <meta name="msvalidate.01" content="3CC0A964D32EA3E8561E23E2DF370684" />
    <meta property="og:title" content="Direct Voxel Grid Optimiztion">
    <meta name="og:description" content="Fast 3D scenes reconstruction from multiple images. DVGO supports bounded inward-facing, unbounded inward-facing (unbounded 360), and forward-facing capturing.">
    <meta property="og:image" content="https://sunset1995.github.io/dvgo/web_preview.jpeg">
    <meta property="og:image:secure_url" content="https://sunset1995.github.io/dvgo/web_preview.jpeg">
    <meta property="og:image:width" content="600">
    <meta property="og:image:height" content="314">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://sunset1995.github.io/dvgo">
    <meta property="og:site_name" content="DVGO">
    <link rel="icon" href="./favicon.ico">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" integrity="sha384-zCbKRCUGaJDkqS1kPbPd7TveP5iyJE0EjAuZQTgFLD2ylzuqKfdKlfG/eSrtxUkn" crossorigin="anonymous">
    <link rel="stylesheet" href="css/style.css">
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <script src="https://kit.fontawesome.com/e5a777658b.js" crossorigin="anonymous"></script>
</head>
<body>
    <div class="container-lg">
        <div class="row mb-2 mt-4" id="paper-title">
            <h1 class="col-md-12 text-center">
                Direct Voxel Grid Optimization
            </h1>
            <h3 class="col-md-12 text-center">
                Super-fast Convergence for Radiance Fields Reconstruction
            </h3>
            <h3 class="col-md-12 text-center">
                <small>CVPR 2022 (Oral)</small>
            </h3>
        </div>

        <div class="row" id="authors">
            <div class="mx-auto text-center">
                <ul class="list-inline mb-0">
                    <li class="list-inline-item">
                        <a href="https://sunset1995.github.io/">Cheng Sun</a>
                    </li>

                    <li class="list-inline-item">
                        <a href="http://aliensunmin.github.io/">Min Sun</a>
                    </li>

                    <li class="list-inline-item">
                        <a href="https://htchen.github.io/">Hwann-Tzong Chen</a>
                    </li>
                </ul>
                <ul class="list-inline mb-0" id="institution">
                    <li class="list-inline-item">
                        National Tsing Hua University
                    </li>
                </ul>
            </div>
        </div>

        <div class="row mb-2" id="links">
            <div class="mx-auto">
                <ul class="nav">
                    <li class="nav-item text-center">
                        <a href="https://arxiv.org/abs/2111.11215" class="nav-link" title="Temp link">
                            <i class="fa-solid fa-file-lines fa-3x"></i>
                            <br>
                            DVGO
                        </a>
                    </li>
                    <li class="nav-item text-center">
                        <a href="https://arxiv.org/abs/2206.05085" class="nav-link" title="Temp link">
                            <i class="fa-solid fa-file-lines fa-3x"></i>
                            <br>
                            DVGOv2
                        </a>
                    </li>
                    <li class="nav-item text-center">
                        <a href="https://youtu.be/gLmujfjRVGw" class="nav-link" title="Temp link">
                            <i class="fa-brands fa-youtube fa-3x"></i>
                            <br>
                            Video
                        </a>
                    </li>
                    <li class="nav-item text-center">
                        <a href="https://github.com/sunset1995/DirectVoxGO" class="nav-link">
                            <i class="fa-brands fa-github fa-3x"></i>
                            <br>
                            Code
                        </a>
                    </li>
                </ul>
            </div>
        </div>

        <div class="row mb-3 pt-2" id="my_teaser">
            <div class="col-md-6 mx-auto">
                <video class="fullwid-vid" autoplay loop muted controls>
                    <source src="https://user-images.githubusercontent.com/2712505/153380311-19d6c3a1-9130-489a-af16-ad36c78f10a9.mp4" type="video/mp4">
                </video>
                <video class="fullwid-vid" autoplay loop muted controls>
                    <source src="https://user-images.githubusercontent.com/2712505/153380197-991d1689-6418-499c-a192-d757f9a64b64.mp4" type="video/mp4">
                </video>
                <img src="img/trainging_time.png" class="img-responsive" alt="training time comparison">
            </div>
        </div>



        <div class="row mb-3 pt-2">
            <div class="col-md-8 mx-auto">
                <h4 class="sec_title">Results on custom casual capturing</h4>
                <p>A <a href="./tutor_forward_facing.html">short guide</a> to support custom forward-facing capturing and fly-through video rendering.</p>
<div id="my_casual_demo" class="carousel slide" data-ride="carousel">
  <div class="carousel-inner">
    <div class="carousel-item active" data-interval="8000">
      <video class="img-fluid" autoplay loop muted controls><source src="https://user-images.githubusercontent.com/2712505/174271503-9d05a469-0acb-40bd-ab0b-6de45fb123fa.mp4" type="video/mp4" /></video>
    </div>
    <div class="carousel-item" data-interval="8000">
      <video class="img-fluid" loop muted controls><source src="https://user-images.githubusercontent.com/2712505/174271488-0d301dcd-5a26-4813-9872-d82736fc62e0.mp4" type="video/mp4" /></video>
    </div>
  </div>
  <a class="carousel-control-prev" href="#my_casual_demo" role="button" data-slide="prev">
    <span class="carousel-control-prev-icon" aria-hidden="true"></span>
    <span class="sr-only">Previous</span>
  </a>
  <a class="carousel-control-next" href="#my_casual_demo" role="button" data-slide="next">
    <span class="carousel-control-next-icon" aria-hidden="true"></span>
    <span class="sr-only">Next</span>
  </a>
</div>
            </div>
        </div>



        <div class="row mb-3 pt-2">
            <div class="col-md-8 mx-auto">
                <h4 class="sec_title">Results on real-world captured data</h4>
<div id="my_videos_demo" class="carousel slide" data-ride="carousel">
  <div class="carousel-inner">
    <div class="carousel-item active" data-interval="3000">
      <video class="img-fluid" autoplay loop muted controls><source src="https://user-images.githubusercontent.com/2712505/171703052-1cdc1fdc-65c8-45f8-b10a-ffc591dd2f47.mp4" type="video/mp4" /></video>
    </div>
    <div class="carousel-item" data-interval="6000">
      <video class="img-fluid" loop muted controls><source src="https://user-images.githubusercontent.com/2712505/174282571-07c1e4d2-b101-4108-b913-a642c1c0db9f.mp4" type="video/mp4" /></video>
    </div>
    <div class="carousel-item" data-interval="3000">
      <video class="img-fluid" loop muted controls><source src="https://user-images.githubusercontent.com/2712505/171703143-e2cb153e-7a75-4a38-b596-47cccbf26f56.mp4" type="video/mp4" /></video>
    </div>
    <div class="carousel-item" data-interval="6000">
      <video class="img-fluid" loop muted controls><source src="https://user-images.githubusercontent.com/2712505/174282530-1fc55da3-2d6c-4689-aae6-71508073fa50.mp4" type="video/mp4" /></video>
    </div>
    <div class="carousel-item" data-interval="3000">
      <video class="img-fluid" loop muted controls><source src="https://user-images.githubusercontent.com/2712505/171703172-338dc031-0a09-492d-8c30-ab5cb5af76f3.mp4" type="video/mp4" /></video>
    </div>
    <div class="carousel-item" data-interval="6000">
      <video class="img-fluid" loop muted controls><source src="https://user-images.githubusercontent.com/2712505/174282592-d1392510-96d2-44df-86eb-d2228a8bc469.mp4" type="video/mp4" /></video>
    </div>
    <div class="carousel-item" data-interval="3000">
      <video class="img-fluid" loop muted controls><source src="https://user-images.githubusercontent.com/2712505/171703628-898fffb5-d929-4115-824f-197569aa16dc.mp4" type="video/mp4" /></video>
    </div>
    <div class="carousel-item" data-interval="6000">
      <video class="img-fluid" loop muted controls><source src="https://user-images.githubusercontent.com/2712505/174282633-f0a29688-d38b-4909-ac5d-153f436e6f1c.mp4" type="video/mp4" /></video>
    </div>
  </div>
  <a class="carousel-control-prev" href="#my_videos_demo" role="button" data-slide="prev">
    <span class="carousel-control-prev-icon" aria-hidden="true"></span>
    <span class="sr-only">Previous</span>
  </a>
  <a class="carousel-control-next" href="#my_videos_demo" role="button" data-slide="next">
    <span class="carousel-control-next-icon" aria-hidden="true"></span>
    <span class="sr-only">Next</span>
  </a>
</div>
            </div>
        </div>

        <div class="row mb-3 pt-2" id="my_features">
            <div class="col-md-8 mx-auto">
                <h4 class="sec_title">Features</h4>
                <ul>
                    <li>Speedup NeRF by replacing the MLP with the voxel grid.</li>
                    <li>Simple scene representation:</li>
                    <ul class="detail">
                        <li class="row"><div class="col-sm-4 pr-0">Volume densities:</div><div class="col-sm-8 pr-0">dense voxel grid (3D).</div></li>
                        <li class="row"><div class="col-sm-4 pr-0">View-dependent colors:</div><div class="col-sm-8 pr-0">dense feature grid (4D) + shallow MLP.</div></li>
                    </ul>
                    <li>Pytorch implementation.</li>
                    <li><sup>&dagger;</sup>Pytorch cuda extention built just-in-time for <b>another 2--3x speedup</b>.</li>
                    <li><sup>&dagger;</sup>O(N) realization for the distortion loss proposed by <a href="https://jonbarron.info/mipnerf360/">mip-nerf 360</a>.</li>
                    <ul>
                        <li>The loss improves our training time and quality.</li>
                        <li>We have released a self-contained pytorch package: <a href="https://github.com/sunset1995/torch_efficient_distloss">torch_efficient_distloss</a>.</li>
                        <li>Consider a batch of 8192 rays X 256 points.</li>
                        <ul>
                            <li>GPU memory consumption: 6192MB => 96MB.</li>
                            <li>Run times for 100 iters: 20 sec => 0.2sec.</li>
                        </ul>
                    </ul>
                    <li>Supported datasets:</li>
                    <ul class="detail">
                        <li class="row"><div class="col-sm-4 pr-0">Bounded inward-facing:</div><div class="col-sm-8 pr-0"><a href="https://drive.google.com/drive/folders/128yBriW1IG_3NJ5Rp7APSTZsJqdJdfc1">NeRF</a>, <a href="https://dl.fbaipublicfiles.com/nsvf/dataset/Synthetic_NSVF.zip">NSVF</a>, <a href="https://dl.fbaipublicfiles.com/nsvf/dataset/BlendedMVS.zip">BlendedMVS</a>, <a href="https://dl.fbaipublicfiles.com/nsvf/dataset/TanksAndTemple.zip">T&T (masked)</a>, <a href="https://drive.google.com/open?id=1ScsRlnzy9Bd_n-xw83SP-0t548v63mPH">DeepVoxels</a>.</div></li>
                        <li class="row"><div class="col-sm-4 pr-0"><sup>&dagger;</sup>Unbounded inward-facing:</div><div class="col-sm-8"><a href="https://drive.google.com/file/d/11KRfN91W1AxAW6lOFs4EeYDbeoQZCi87/view?usp=sharing">T&T</a>, <a href="https://drive.google.com/file/d/1gsjDjkbTh4GAR9fFqlIDZ__qR9NYTURQ/view?usp=sharing">LF</a>, <a href="https://jonbarron.info/mipnerf360/">mip-NeRF360</a>.</div></li>
                        <li class="row"><div class="col-sm-4 pr-0"><sup>&dagger;</sup>Foward-facing:</div><div class="col-sm-8 pr-0"><a href="https://drive.google.com/drive/folders/14boI-o5hGO9srnWaaogTU5_ji7wkX2S7">LLFF</a>.</div></li>
                    </ul>
                </ul>
                <p><sup>&dagger; means new stuff after publication.</sup></p>
            </div>
        </div>

        <div class="row mb-3 pt-2" id="my_motivation">
            <div class="col-md-8 mx-auto">
                <h4 class="sec_title">Motivation</h4>
                <ul>
                    <li>NeRF</li>
                    <ul>
                        <li>ðŸ˜€ Excellent quality & flexibility.</li>
                        <li>ðŸ˜• Very slow due to MLP queries.</li>
                    </ul>
                    <li>Replacing the MLP with voxel grid.</li>
                    <ul>
                        <li>ðŸ˜€ Previous works<sup>[1,2,3]</sup> have shown a large inference time speedup with good quality.</li>
                        <li>ðŸ˜• Limited to inference time. Pre-trained MLP is required.</li>
                    </ul>
                    <li>ðŸ¤” How to train voxel grid directly from scratch?</li>
                </ul>
                <ul class="list-unstyled">
                    <li><sup><a href="https://alexyu.net/plenoctrees/">[1]</a> PlenOctrees for Real-time Rendering of Neural Radiance Fields, Yu et al.</sup></li>
                    <li><sup><a href="https://microsoft.github.io/FastNeRF/">[2]</a> FastNeRF: High-Fidelity Neural Rendering at 200FPS, Garbin et al.</sup></li>
                    <li><sup><a href="https://phog.github.io/snerg/">[3]</a> Baking Neural Radiance Fields for Real-Time View Synthesis, Hedman et al.</sup></li>
                </ul>
            </div>
        </div>

        <div class="row mb-3 pt-2" id="my_postact">
            <div class="col-md-8 mx-auto">
                <h4 class="sec_title">Post-activation</h4>

                <b>Observation.</b>
                To produce sharp surface, we have to activate density into alpha <u>after</u> interpolation.
                <div class="row justify-content-center">
                    <div class="col-8">
                        <img src="img/post_act.png" class="img-responsive">
                    </div>
                </div>
                <p></p>

                <p><b>Proof.</b> Post-activation can be arbitrarily close to a surface beyond linear. Detail in paper.</p>
                <b>Toy example 1.</b> Fitting a surface with a single 2D grid cell.
                <div class="row justify-content-center">
                    <div class="col-6">
                        <img src="img/post_toy1.png" class="img-responsive">
                    </div>
                </div>
                <p></p>

                <b>Toy example 2.</b> Fitting a binary (occupancy) image with a 2D grid.
                <div class="row justify-content-center">
                    <div class="col-9">
                        <img src="img/post_toy2.png" class="img-responsive">
                    </div>
                </div>
                <p></p>

                <p>
                    <b>Ablation study.</b> Up to 2.88 PSNR difference for novel-view synthesis.
                </p>
            </div>
        </div>

        <div class="row mb-3 pt-2" id="my_init">
            <div class="col-md-8 mx-auto">
                <h4 class="sec_title">Low-density initialization</h4>
                <p>
                    <b>Observation.</b>
                    The initial alpha values (activated from the volume densities) should be close to 0.
                    We introduce a hyperparameter <code>alpha-init</code> to control it.
                </p>

                <b>Ablation study.</b>
                The <code>alpha-init</code> should be small enough to achieve good quality and avoid <span style="color: rgb(255, 150, 141); font-weight: 900;">floater</span>.
                <div class="row justify-content-center">
                    <div class="col-9">
                        <img src="img/low_density.png" class="img-responsive">
                    </div>
                </div>
                <p></p>

                <p class="text-justify">
                    <b>Caveat.</b>
                    We empirically find that the qualities and the training times are sensitive to the <code>alpha-init</code>. We set <code>alpha-init</code> to 3 different values for bounded, unbounded inward-facing, and forward-facining datasets respectively. You may want to try a few different values for new datasets.
                </p>

                <p class="text-justify">
                    <b>ðŸ¤”</b>
                    It seems that the explicit (grid-based) representation needs careful regularizations, while the implicit (MLP network) doesn't.
                    We still don't know the root cause for this empirical finding at this moment.
                </p>
            </div>
        </div>

        <div class="row mb-3" id="related_work">
            <div class="col-md-8 mx-auto">
                <h4 class="sec_title">Advanced Data Structure</h4>
                Some concurrent works have used a more advanced data structure:
                <ul>
                    <li>
                        Sparse grid â€” Plenoxels: Radiance Fields without Neural Networks. <a href="https://alexyu.net/plenoxels/"><i class="fa-solid fa-arrow-up-right-from-square"></i></a>
                    </li>
                    <li>Hash â€” Instant Neural Graphics Primitives with a Multiresolution Hash Encoding. <a href="https://nvlabs.github.io/instant-ngp/"><i class="fa-solid fa-arrow-up-right-from-square"></i></a></li>
                    <li>Factorized components â€” TensoRF: Tensorial Radiance Fields. <a href="https://apchenstu.github.io/TensoRF/"><i class="fa-solid fa-arrow-up-right-from-square"></i></a></li>
                </ul>
                <p>You will need them for scaling to a higher grid resolution. But we believe <b>our simplest dense grid could still be your good starting point</b> if you have other challenging problems to deal with.</p>
            </div>
        </div>

        <div class="row mb-4" id="my_bibtex">
            <div class="col-md-8 mx-auto">
                <h4 class="sec_title">Citation</h4>
                <pre><code style="font-size: 0.8em;">@inproceedings{SunSC22,
  author    = {Cheng Sun and Min Sun and Hwann{-}Tzong Chen},
  title     = {Direct Voxel Grid Optimization: Super-fast Convergence for Radiance Fields Reconstruction},
  booktitle = {CVPR},
  year      = {2022},
}</code></pre>
            </div>
        </div>

        <div class="row mb-3">
            <div class="col-md-8 mx-auto">
                <h4 class="sec_title">Acknowledgements</h4>
                <p class="text-justify">
                    This work was supported in part by the MOST grants 110-2634-F-001-009 and 110-2622-8-007-010-TE2 of Taiwan. We are grateful to National Center for High-performance Computing for providing computational resources and facilities.
                </p>
                <p class="text-justify">
                    This website is in part based on a template of <a href="http://mgharbi.com/">Micha&euml;l Gharbi</a>.
                </p>
            </div>
        </div>
    </div> <!-- container -->

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2" crossorigin="anonymous"></script>
    <script type="text/javascript">
        // Download video only when active (speedup website loading & network traffic)
        $(".carousel").on('slide.bs.carousel', function(ev) {
            let slides = $(this).find('.carousel-item');
            let vid = slides[ev.to].querySelectorAll('video')[0];
            let isPlaying = vid.currentTime > 0 && vid.readyState > 2;
            if(!isPlaying) {
                vid.play();
            }
        });

        $(window).on('ready load resize', function() {
            let carousel_width = $(".carousel").width();
            let carousel_height = 0.7619047619047619 * carousel_width;
            // Math.max.apply(null, $(".carousel video").map(function() {
            //     let h = $(this)[0].videoHeight;
            //     let w = $(this)[0].videoWidth;
            //     return h * carousel_width / w;
            // }).get());
            $(".carousel video").height(carousel_height);
        });
    </script>
</body>

</html>